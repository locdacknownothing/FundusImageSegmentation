{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwnet-header"
   },
   "source": [
    "# LWNet Reproduction - Google Colab\n",
    "\n",
    "This notebook allows you to reproduce LWNet (The Little W-Net That Could) results using Google Colab's free GPU.\n",
    "\n",
    "**Paper:** [The Little W-Net That Could: State-of-the-Art Retinal Vessel Segmentation with Minimalistic Models](https://arxiv.org/abs/2009.01907)\n",
    "\n",
    "**Original Repository:** [agaldran/lwnet](https://github.com/agaldran/lwnet)\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Enable GPU**: Runtime → Change runtime type → Hardware accelerator → GPU\n",
    "2. Run cells sequentially from top to bottom\n",
    "3. Training will use Colab's GPU (Tesla T4 or similar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check-gpu"
   },
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gpu-check-code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "GPU: Tesla T4\n",
      "CUDA version: 12.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"⚠️ GPU not available! Please enable GPU in Runtime → Change runtime type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone-repo"
   },
   "source": [
    "## 2. Clone Your Repository\n",
    "\n",
    "Replace the repository URL with your repository URL if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && rm -rf /content/lwnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'lwnet'...\n",
      "remote: Enumerating objects: 1198, done.\u001b[K\n",
      "remote: Counting objects: 100% (346/346), done.\u001b[K\n",
      "remote: Compressing objects: 100% (278/278), done.\u001b[K\n",
      "remote: Total 1198 (delta 100), reused 309 (delta 66), pack-reused 852 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1198/1198), 22.42 MiB | 25.25 MiB/s, done.\n",
      "Resolving deltas: 100% (603/603), done.\n",
      "✓ Repository cloned successfully\n",
      "/content/lwnet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Clone the main repository\n",
    "if not os.path.exists('lwnet'):\n",
    "    # TODO: fix code to be compatible with conda, push to personal repo and clone\n",
    "    !git clone --recurse-submodules https://github.com/agaldran/lwnet.git\n",
    "    print(\"✓ Repository cloned successfully\")\n",
    "else:\n",
    "    print(\"✓ Repository already exists\")\n",
    "\n",
    "# Navigate to lwnet directory\n",
    "%cd lwnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-deps"
   },
   "source": [
    "## 3. Install Dependencies\n",
    "\n",
    "Installing required packages for LWNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-26 17:27:46--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
      "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:bf9e, ...\n",
      "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 157891003 (151M) [application/octet-stream]\n",
      "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
      "\n",
      "Miniconda3-latest-L 100%[===================>] 150.58M   230MB/s    in 0.7s    \n",
      "\n",
      "2025-11-26 17:27:46 (230 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [157891003/157891003]\n",
      "\n",
      "PREFIX=/usr/local\n",
      "Unpacking bootstrapper...\n",
      "Unpacking payload...\n",
      "\n",
      "Installing base environment...\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "installation finished.\n",
      "WARNING:\n",
      "    You currently have a PYTHONPATH environment variable set. This may cause\n",
      "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
      "    For best results, please verify that your PYTHONPATH only points to\n",
      "    directories of packages that are compatible with the Python interpreter\n",
      "    in Miniconda3: /usr/local\n",
      "accepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/main\u001b[0m\n",
      "accepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/r\u001b[0m\n",
      "\u001b[1;33mJupyter detected\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[1;32m2\u001b[0m\u001b[1;32m channel Terms of Service accepted\u001b[0m\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local/envs/lwnet\n",
      "\n",
      "  added / updated specs:\n",
      "    - pkgs/main/linux-64::_libgcc_mutex==0.1=main\n",
      "    - pkgs/main/linux-64::_pytorch_select==0.2=gpu_0\n",
      "    - pkgs/main/linux-64::blas==1.0=mkl\n",
      "    - pkgs/main/linux-64::ca-certificates==2020.7.22=0\n",
      "    - pkgs/main/linux-64::certifi==2020.6.20=py37_0\n",
      "    - pkgs/main/linux-64::cffi==1.14.2=py37he30daa8_0\n",
      "    - pkgs/main/linux-64::cudatoolkit==10.0.130=0\n",
      "    - pkgs/main/linux-64::cudnn==7.6.5=cuda10.0_0\n",
      "    - pkgs/main/linux-64::cycler==0.10.0=py37_0\n",
      "    - pkgs/main/linux-64::cytoolz==0.10.1=py37h7b6447c_0\n",
      "    - pkgs/main/linux-64::dbus==1.13.16=hb2f20db_0\n",
      "    - pkgs/main/linux-64::expat==2.2.9=he6710b0_2\n",
      "    - pkgs/main/linux-64::fontconfig==2.13.0=h9420a91_0\n",
      "    - pkgs/main/linux-64::freetype==2.10.2=h5ab3b9f_0\n",
      "    - pkgs/main/linux-64::glib==2.65.0=h3eb4bd4_0\n",
      "    - pkgs/main/linux-64::gst-plugins-base==1.14.0=hbbd80ab_1\n",
      "    - pkgs/main/linux-64::gstreamer==1.14.0=hb31296c_0\n",
      "    - pkgs/main/linux-64::icu==58.2=he6710b0_3\n",
      "    - pkgs/main/linux-64::intel-openmp==2020.2=254\n",
      "    - pkgs/main/linux-64::jpeg==9b=h024ee3a_2\n",
      "    - pkgs/main/linux-64::kiwisolver==1.2.0=py37hfd86e86_0\n",
      "    - pkgs/main/linux-64::lcms2==2.11=h396b838_0\n",
      "    - pkgs/main/linux-64::ld_impl_linux-64==2.33.1=h53a641e_7\n",
      "    - pkgs/main/linux-64::libedit==3.1.20191231=h14c3975_1\n",
      "    - pkgs/main/linux-64::libffi==3.3=he6710b0_2\n",
      "    - pkgs/main/linux-64::libgcc-ng==9.1.0=hdf63c60_0\n",
      "    - pkgs/main/linux-64::libgfortran-ng==7.3.0=hdf63c60_0\n",
      "    - pkgs/main/linux-64::libpng==1.6.37=hbc83047_0\n",
      "    - pkgs/main/linux-64::libstdcxx-ng==9.1.0=hdf63c60_0\n",
      "    - pkgs/main/linux-64::libtiff==4.1.0=h2733197_1\n",
      "    - pkgs/main/linux-64::libuuid==1.0.3=h1bed415_2\n",
      "    - pkgs/main/linux-64::libxcb==1.14=h7b6447c_0\n",
      "    - pkgs/main/linux-64::libxml2==2.9.10=he19cac6_1\n",
      "    - pkgs/main/linux-64::lz4-c==1.9.2=he6710b0_1\n",
      "    - pkgs/main/linux-64::matplotlib-base==3.3.1=py37h817c723_0\n",
      "    - pkgs/main/linux-64::matplotlib==3.3.1=0\n",
      "    - pkgs/main/linux-64::mkl-service==2.3.0=py37he904b0f_0\n",
      "    - pkgs/main/linux-64::mkl==2020.2=256\n",
      "    - pkgs/main/linux-64::mkl_fft==1.1.0=py37h23d657b_0\n",
      "    - pkgs/main/linux-64::mkl_random==1.1.1=py37h0573a6f_0\n",
      "    - pkgs/main/linux-64::ncurses==6.2=he6710b0_1\n",
      "    - pkgs/main/linux-64::ninja==1.10.0=py37hfd86e86_0\n",
      "    - pkgs/main/linux-64::numpy-base==1.19.1=py37hfa32c7d_0\n",
      "    - pkgs/main/linux-64::numpy==1.19.1=py37hbc911f0_0\n",
      "    - pkgs/main/linux-64::olefile==0.46=py37_0\n",
      "    - pkgs/main/linux-64::openssl==1.1.1g=h7b6447c_0\n",
      "    - pkgs/main/linux-64::pandas==1.1.1=py37he6710b0_0\n",
      "    - pkgs/main/linux-64::pcre==8.44=he6710b0_0\n",
      "    - pkgs/main/linux-64::pillow==7.2.0=py37hb39fc2d_0\n",
      "    - pkgs/main/linux-64::pip==20.2.2=py37_0\n",
      "    - pkgs/main/linux-64::pyqt==5.9.2=py37h05f1152_2\n",
      "    - pkgs/main/linux-64::python==3.7.7=hcff3b4d_5\n",
      "    - pkgs/main/linux-64::pytorch==1.3.1=cuda100py37h53c1284_0\n",
      "    - pkgs/main/linux-64::pywavelets==1.1.1=py37h7b6447c_0\n",
      "    - pkgs/main/linux-64::pyyaml==5.3.1=py37h7b6447c_1\n",
      "    - pkgs/main/linux-64::qt==5.9.7=h5867ecd_1\n",
      "    - pkgs/main/linux-64::readline==8.0=h7b6447c_0\n",
      "    - pkgs/main/linux-64::scikit-image==0.16.2=py37h0573a6f_0\n",
      "    - pkgs/main/linux-64::scikit-learn==0.23.2=py37h0573a6f_0\n",
      "    - pkgs/main/linux-64::scipy==1.5.2=py37h0b6359f_0\n",
      "    - pkgs/main/linux-64::setuptools==49.6.0=py37_0\n",
      "    - pkgs/main/linux-64::sip==4.19.8=py37hf484d3e_0\n",
      "    - pkgs/main/linux-64::sqlite==3.33.0=h62c20be_0\n",
      "    - pkgs/main/linux-64::tk==8.6.10=hbc83047_0\n",
      "    - pkgs/main/linux-64::torchvision==0.4.2=cuda100py37hecfc37a_0\n",
      "    - pkgs/main/linux-64::tornado==6.0.4=py37h7b6447c_1\n",
      "    - pkgs/main/linux-64::xz==5.2.5=h7b6447c_0\n",
      "    - pkgs/main/linux-64::yaml==0.2.5=h7b6447c_0\n",
      "    - pkgs/main/linux-64::zlib==1.2.11=h7b6447c_3\n",
      "    - pkgs/main/linux-64::zstd==1.4.5=h9ceee32_0\n",
      "    - pkgs/main/noarch::cloudpickle==1.5.0=py_0\n",
      "    - pkgs/main/noarch::dask-core==2.24.0=py_0\n",
      "    - pkgs/main/noarch::decorator==4.4.2=py_0\n",
      "    - pkgs/main/noarch::imageio==2.9.0=py_0\n",
      "    - pkgs/main/noarch::joblib==0.16.0=py_0\n",
      "    - pkgs/main/noarch::networkx==2.5=py_0\n",
      "    - pkgs/main/noarch::pycparser==2.20=py_2\n",
      "    - pkgs/main/noarch::pyparsing==2.4.7=py_0\n",
      "    - pkgs/main/noarch::python-dateutil==2.8.1=py_0\n",
      "    - pkgs/main/noarch::pytz==2020.1=py_0\n",
      "    - pkgs/main/noarch::six==1.15.0=py_0\n",
      "    - pkgs/main/noarch::threadpoolctl==2.1.0=pyh5ca1d4c_0\n",
      "    - pkgs/main/noarch::toolz==0.10.0=py_0\n",
      "    - pkgs/main/noarch::tqdm==4.48.2=py_0\n",
      "    - pkgs/main/noarch::wheel==0.35.1=py_0\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
      "  _pytorch_select    pkgs/main/linux-64::_pytorch_select-0.2-gpu_0 \n",
      "  blas               pkgs/main/linux-64::blas-1.0-mkl \n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.7.22-0 \n",
      "  certifi            pkgs/main/linux-64::certifi-2020.6.20-py37_0 \n",
      "  cffi               pkgs/main/linux-64::cffi-1.14.2-py37he30daa8_0 \n",
      "  cloudpickle        pkgs/main/noarch::cloudpickle-1.5.0-py_0 \n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0 \n",
      "  cudnn              pkgs/main/linux-64::cudnn-7.6.5-cuda10.0_0 \n",
      "  cycler             pkgs/main/linux-64::cycler-0.10.0-py37_0 \n",
      "  cytoolz            pkgs/main/linux-64::cytoolz-0.10.1-py37h7b6447c_0 \n",
      "  dask-core          pkgs/main/noarch::dask-core-2.24.0-py_0 \n",
      "  dbus               pkgs/main/linux-64::dbus-1.13.16-hb2f20db_0 \n",
      "  decorator          pkgs/main/noarch::decorator-4.4.2-py_0 \n",
      "  expat              pkgs/main/linux-64::expat-2.2.9-he6710b0_2 \n",
      "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.0-h9420a91_0 \n",
      "  freetype           pkgs/main/linux-64::freetype-2.10.2-h5ab3b9f_0 \n",
      "  glib               pkgs/main/linux-64::glib-2.65.0-h3eb4bd4_0 \n",
      "  gst-plugins-base   pkgs/main/linux-64::gst-plugins-base-1.14.0-hbbd80ab_1 \n",
      "  gstreamer          pkgs/main/linux-64::gstreamer-1.14.0-hb31296c_0 \n",
      "  icu                pkgs/main/linux-64::icu-58.2-he6710b0_3 \n",
      "  imageio            pkgs/main/noarch::imageio-2.9.0-py_0 \n",
      "  intel-openmp       pkgs/main/linux-64::intel-openmp-2020.2-254 \n",
      "  joblib             pkgs/main/noarch::joblib-0.16.0-py_0 \n",
      "  jpeg               pkgs/main/linux-64::jpeg-9b-h024ee3a_2 \n",
      "  kiwisolver         pkgs/main/linux-64::kiwisolver-1.2.0-py37hfd86e86_0 \n",
      "  lcms2              pkgs/main/linux-64::lcms2-2.11-h396b838_0 \n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7 \n",
      "  libedit            pkgs/main/linux-64::libedit-3.1.20191231-h14c3975_1 \n",
      "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2 \n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0 \n",
      "  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-7.3.0-hdf63c60_0 \n",
      "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0 \n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0 \n",
      "  libtiff            pkgs/main/linux-64::libtiff-4.1.0-h2733197_1 \n",
      "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h1bed415_2 \n",
      "  libxcb             pkgs/main/linux-64::libxcb-1.14-h7b6447c_0 \n",
      "  libxml2            pkgs/main/linux-64::libxml2-2.9.10-he19cac6_1 \n",
      "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.2-he6710b0_1 \n",
      "  matplotlib         pkgs/main/linux-64::matplotlib-3.3.1-0 \n",
      "  matplotlib-base    pkgs/main/linux-64::matplotlib-base-3.3.1-py37h817c723_0 \n",
      "  mkl                pkgs/main/linux-64::mkl-2020.2-256 \n",
      "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py37he904b0f_0 \n",
      "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.1.0-py37h23d657b_0 \n",
      "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.1-py37h0573a6f_0 \n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1 \n",
      "  networkx           pkgs/main/noarch::networkx-2.5-py_0 \n",
      "  ninja              pkgs/main/linux-64::ninja-1.10.0-py37hfd86e86_0 \n",
      "  numpy              pkgs/main/linux-64::numpy-1.19.1-py37hbc911f0_0 \n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.19.1-py37hfa32c7d_0 \n",
      "  olefile            pkgs/main/linux-64::olefile-0.46-py37_0 \n",
      "  openssl            pkgs/main/linux-64::openssl-1.1.1g-h7b6447c_0 \n",
      "  pandas             pkgs/main/linux-64::pandas-1.1.1-py37he6710b0_0 \n",
      "  pcre               pkgs/main/linux-64::pcre-8.44-he6710b0_0 \n",
      "  pillow             pkgs/main/linux-64::pillow-7.2.0-py37hb39fc2d_0 \n",
      "  pip                pkgs/main/linux-64::pip-20.2.2-py37_0 \n",
      "  pycparser          pkgs/main/noarch::pycparser-2.20-py_2 \n",
      "  pyparsing          pkgs/main/noarch::pyparsing-2.4.7-py_0 \n",
      "  pyqt               pkgs/main/linux-64::pyqt-5.9.2-py37h05f1152_2 \n",
      "  python             pkgs/main/linux-64::python-3.7.7-hcff3b4d_5 \n",
      "  python-dateutil    pkgs/main/noarch::python-dateutil-2.8.1-py_0 \n",
      "  pytorch            pkgs/main/linux-64::pytorch-1.3.1-cuda100py37h53c1284_0 \n",
      "  pytz               pkgs/main/noarch::pytz-2020.1-py_0 \n",
      "  pywavelets         pkgs/main/linux-64::pywavelets-1.1.1-py37h7b6447c_0 \n",
      "  pyyaml             pkgs/main/linux-64::pyyaml-5.3.1-py37h7b6447c_1 \n",
      "  qt                 pkgs/main/linux-64::qt-5.9.7-h5867ecd_1 \n",
      "  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0 \n",
      "  scikit-image       pkgs/main/linux-64::scikit-image-0.16.2-py37h0573a6f_0 \n",
      "  scikit-learn       pkgs/main/linux-64::scikit-learn-0.23.2-py37h0573a6f_0 \n",
      "  scipy              pkgs/main/linux-64::scipy-1.5.2-py37h0b6359f_0 \n",
      "  setuptools         pkgs/main/linux-64::setuptools-49.6.0-py37_0 \n",
      "  sip                pkgs/main/linux-64::sip-4.19.8-py37hf484d3e_0 \n",
      "  six                pkgs/main/noarch::six-1.15.0-py_0 \n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.33.0-h62c20be_0 \n",
      "  threadpoolctl      pkgs/main/noarch::threadpoolctl-2.1.0-pyh5ca1d4c_0 \n",
      "  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0 \n",
      "  toolz              pkgs/main/noarch::toolz-0.10.0-py_0 \n",
      "  torchvision        pkgs/main/linux-64::torchvision-0.4.2-cuda100py37hecfc37a_0 \n",
      "  tornado            pkgs/main/linux-64::tornado-6.0.4-py37h7b6447c_1 \n",
      "  tqdm               pkgs/main/noarch::tqdm-4.48.2-py_0 \n",
      "  wheel              pkgs/main/noarch::wheel-0.35.1-py_0 \n",
      "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0 \n",
      "  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0 \n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3 \n",
      "  zstd               pkgs/main/linux-64::zstd-1.4.5-h9ceee32_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate lwnet\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\u001b[1;33mJupyter detected\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[1;32m2\u001b[0m\u001b[1;32m channel Terms of Service accepted\u001b[0m\n",
      "Channels:\n",
      " - pytorch\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.9.1\n",
      "    latest version: 25.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local/envs/lwnet\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch=1.8.0\n",
      "    - torchvision=0.9.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    bzip2-1.0.8                |       h7b6447c_0          78 KB\n",
      "    certifi-2022.12.7          |   py37h06a4308_0         150 KB\n",
      "    ffmpeg-4.3                 |       hf484d3e_0         9.9 MB  pytorch\n",
      "    flit-core-3.6.0            |     pyhd3eb1b0_0          42 KB\n",
      "    gmp-6.2.1                  |       h295c915_3         544 KB\n",
      "    libiconv-1.16              |       h7f8727e_2         736 KB\n",
      "    libidn2-2.3.2              |       h7f8727e_0          81 KB\n",
      "    libtasn1-4.16.0            |       h27cfd23_0          58 KB\n",
      "    libuv-1.40.0               |       h7b6447c_0         736 KB\n",
      "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
      "    pytorch-1.8.0              |      py3.7_cpu_0        65.9 MB  pytorch\n",
      "    torchvision-0.9.0          |         py37_cpu        21.9 MB  pytorch\n",
      "    typing_extensions-4.4.0    |   py37h06a4308_0          45 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       103.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0 \n",
      "  ffmpeg             pytorch/linux-64::ffmpeg-4.3-hf484d3e_0 \n",
      "  flit-core          pkgs/main/noarch::flit-core-3.6.0-pyhd3eb1b0_0 \n",
      "  gmp                pkgs/main/linux-64::gmp-6.2.1-h295c915_3 \n",
      "  gnutls             pkgs/main/linux-64::gnutls-3.6.15-he1e5248_0 \n",
      "  lame               pkgs/main/linux-64::lame-3.100-h7b6447c_0 \n",
      "  libiconv           pkgs/main/linux-64::libiconv-1.16-h7f8727e_2 \n",
      "  libidn2            pkgs/main/linux-64::libidn2-2.3.2-h7f8727e_0 \n",
      "  libtasn1           pkgs/main/linux-64::libtasn1-4.16.0-h27cfd23_0 \n",
      "  libunistring       pkgs/main/linux-64::libunistring-0.9.10-h27cfd23_0 \n",
      "  libuv              pkgs/main/linux-64::libuv-1.40.0-h7b6447c_0 \n",
      "  nettle             pkgs/main/linux-64::nettle-3.7.3-hbbd107a_1 \n",
      "  openh264           pkgs/main/linux-64::openh264-2.1.1-h4ff587b_0 \n",
      "  typing_extensions  pkgs/main/linux-64::typing_extensions-4.4.0-py37h06a4308_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                               2020.7.22-0 --> 2025.11.4-h06a4308_0 \n",
      "  certifi                                  2020.6.20-py37_0 --> 2022.12.7-py37h06a4308_0 \n",
      "  openssl                                 1.1.1g-h7b6447c_0 --> 1.1.1w-h7f8727e_0 \n",
      "  pytorch            pkgs/main::pytorch-1.3.1-cuda100py37h~ --> pytorch::pytorch-1.8.0-py3.7_cpu_0 \n",
      "  torchvision        pkgs/main::torchvision-0.4.2-cuda100p~ --> pytorch::torchvision-0.9.0-py37_cpu \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n",
      "✓ Conda installed and environment created\n"
     ]
    }
   ],
   "source": [
    "# Install Conda (Miniconda)\n",
    "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
    "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
    "\n",
    "# Add Conda to path\n",
    "# import sys\n",
    "# sys.path.append('/usr/local/lib/python3.8/site-packages')\n",
    "\n",
    "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
    "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
    "\n",
    "# Create environment and install dependencies based on LWNet guide\n",
    "# Note: Adjust python version if specific requirement exists in guide\n",
    "# !conda env remove --name lwnet -y\n",
    "!conda create -n lwnet --file environment.txt -y\n",
    "# !source activate lwnet && conda install pytorch=1.8.0 torchvision=0.9.0 -c pytorch -y\n",
    "\n",
    "print(\"✓ Conda installed and environment created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-data"
   },
   "source": [
    "## 4. Download Public Datasets\n",
    "\n",
    "This will download 7 public datasets (DRIVE, CHASE-DB, HRF, STARE, IOSTAR, ARIA, RC-SLO).\n",
    "\n",
    "**Note:** This may take 10-15 minutes depending on your connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "download-code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading data\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 91.2M    0 91.2M    0     0  21.4M      0 --:--:--  0:00:04 --:--:-- 21.4M\n",
      "--2025-11-26 17:32:21--  http://webeye.ophth.uiowa.edu/abramoff/AV_groundTruth.zip\n",
      "Resolving webeye.ophth.uiowa.edu (webeye.ophth.uiowa.edu)... 129.255.116.103\n",
      "Connecting to webeye.ophth.uiowa.edu (webeye.ophth.uiowa.edu)|129.255.116.103|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30174977 (29M) [application/x-zip-compressed]\n",
      "Saving to: ‘AV_groundTruth.zip’\n",
      "\n",
      "AV_groundTruth.zip  100%[===================>]  28.78M  2.72MB/s    in 11s     \n",
      "\n",
      "2025-11-26 17:32:32 (2.61 MB/s) - ‘AV_groundTruth.zip’ saved [30174977/30174977]\n",
      "\n",
      "Archive:  AV_groundTruth.zip\n",
      "   creating: data/DRIVE/AV_groundTruth/\n",
      "   creating: data/DRIVE/AV_groundTruth/test/\n",
      "   creating: data/DRIVE/AV_groundTruth/test/vessel/\n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/01_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/02_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/03_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/04_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/05_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/06_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/07_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/08_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/09_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/10_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/11_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/12_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/13_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/14_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/15_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/16_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/17_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/18_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/19_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/vessel/20_test.png  \n",
      "   creating: data/DRIVE/AV_groundTruth/test/av/\n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/01_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/02_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/03_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/04_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/05_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/06_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/07_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/08_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/09_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/10_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/11_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/12_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/13_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/14_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/15_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/16_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/17_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/18_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/19_test.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/av/20_test.png  \n",
      "   creating: data/DRIVE/AV_groundTruth/test/images/\n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/01_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/02_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/03_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/04_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/05_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/06_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/07_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/08_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/09_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/10_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/11_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/12_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/13_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/14_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/15_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/16_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/17_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/18_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/19_test.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/test/images/20_test.tif  \n",
      "   creating: data/DRIVE/AV_groundTruth/training/\n",
      "   creating: data/DRIVE/AV_groundTruth/training/av/\n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/21_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/22_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/23_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/24_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/25_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/26_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/27_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/28_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/29_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/30_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/31_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/32_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/33_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/35_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/36_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/37_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/38_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/39_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/40_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/av/34_training.png  \n",
      "   creating: data/DRIVE/AV_groundTruth/training/vessel/\n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/21_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/22_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/23_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/24_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/25_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/26_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/27_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/28_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/29_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/30_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/31_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/32_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/33_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/35_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/36_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/37_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/38_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/39_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/40_training.png  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/vessel/34_training.png  \n",
      "   creating: data/DRIVE/AV_groundTruth/training/images/\n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/21_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/22_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/23_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/24_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/25_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/26_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/27_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/28_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/29_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/30_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/31_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/32_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/33_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/34_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/35_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/36_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/37_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/38_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/39_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/training/images/40_training.tif  \n",
      "  inflating: data/DRIVE/AV_groundTruth/read_me.txt  \n",
      "  inflating: data/DRIVE/AV_groundTruth/introduction.txt  \n",
      "--2025-11-26 17:32:32--  https://www5.cs.fau.de/fileadmin/research/datasets/fundus-images/all.zip\n",
      "Resolving www5.cs.fau.de (www5.cs.fau.de)... 131.188.35.25\n",
      "Connecting to www5.cs.fau.de (www5.cs.fau.de)|131.188.35.25|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 76317613 (73M) [application/zip]\n",
      "Saving to: ‘all.zip’\n",
      "\n",
      "all.zip             100%[===================>]  72.78M  21.6MB/s    in 4.3s    \n",
      "\n",
      "2025-11-26 17:32:37 (17.1 MB/s) - ‘all.zip’ saved [76317613/76317613]\n",
      "\n",
      "Archive:  all.zip\n",
      "   creating: data/HRF/images/\n",
      "  inflating: data/HRF/images/01_dr.JPG  \n",
      "  inflating: data/HRF/images/01_g.jpg  \n",
      "  inflating: data/HRF/images/01_h.jpg  \n",
      "  inflating: data/HRF/images/02_dr.JPG  \n",
      "  inflating: data/HRF/images/02_g.jpg  \n",
      "  inflating: data/HRF/images/02_h.jpg  \n",
      "  inflating: data/HRF/images/03_dr.JPG  \n",
      "  inflating: data/HRF/images/03_g.jpg  \n",
      "  inflating: data/HRF/images/03_h.jpg  \n",
      "  inflating: data/HRF/images/04_dr.JPG  \n",
      "  inflating: data/HRF/images/04_g.jpg  \n",
      "  inflating: data/HRF/images/04_h.jpg  \n",
      "  inflating: data/HRF/images/05_dr.JPG  \n",
      "  inflating: data/HRF/images/05_g.jpg  \n",
      "  inflating: data/HRF/images/05_h.jpg  \n",
      "  inflating: data/HRF/images/06_dr.JPG  \n",
      "  inflating: data/HRF/images/06_g.jpg  \n",
      "  inflating: data/HRF/images/06_h.jpg  \n",
      "  inflating: data/HRF/images/07_dr.JPG  \n",
      "  inflating: data/HRF/images/07_g.jpg  \n",
      "  inflating: data/HRF/images/07_h.jpg  \n",
      "  inflating: data/HRF/images/08_dr.JPG  \n",
      "  inflating: data/HRF/images/08_g.jpg  \n",
      "  inflating: data/HRF/images/08_h.jpg  \n",
      "  inflating: data/HRF/images/09_dr.JPG  \n",
      "  inflating: data/HRF/images/09_g.jpg  \n",
      "  inflating: data/HRF/images/09_h.jpg  \n",
      "  inflating: data/HRF/images/10_dr.JPG  \n",
      "  inflating: data/HRF/images/10_g.jpg  \n",
      "  inflating: data/HRF/images/10_h.jpg  \n",
      "  inflating: data/HRF/images/11_dr.JPG  \n",
      "  inflating: data/HRF/images/11_g.jpg  \n",
      "  inflating: data/HRF/images/11_h.jpg  \n",
      "  inflating: data/HRF/images/12_dr.JPG  \n",
      "  inflating: data/HRF/images/12_g.jpg  \n",
      "  inflating: data/HRF/images/12_h.jpg  \n",
      "  inflating: data/HRF/images/13_dr.JPG  \n",
      "  inflating: data/HRF/images/13_g.jpg  \n",
      "  inflating: data/HRF/images/13_h.jpg  \n",
      "  inflating: data/HRF/images/14_dr.JPG  \n",
      "  inflating: data/HRF/images/14_g.jpg  \n",
      "  inflating: data/HRF/images/14_h.jpg  \n",
      "  inflating: data/HRF/images/15_dr.JPG  \n",
      "  inflating: data/HRF/images/15_g.jpg  \n",
      "  inflating: data/HRF/images/15_h.jpg  \n",
      "   creating: data/HRF/manual1/\n",
      "  inflating: data/HRF/manual1/01_dr.tif  \n",
      "  inflating: data/HRF/manual1/01_g.tif  \n",
      "  inflating: data/HRF/manual1/01_h.tif  \n",
      "  inflating: data/HRF/manual1/02_dr.tif  \n",
      "  inflating: data/HRF/manual1/02_g.tif  \n",
      "  inflating: data/HRF/manual1/02_h.tif  \n",
      "  inflating: data/HRF/manual1/03_dr.tif  \n",
      "  inflating: data/HRF/manual1/03_g.tif  \n",
      "  inflating: data/HRF/manual1/03_h.tif  \n",
      "  inflating: data/HRF/manual1/04_dr.tif  \n",
      "  inflating: data/HRF/manual1/04_g.tif  \n",
      "  inflating: data/HRF/manual1/04_h.tif  \n",
      "  inflating: data/HRF/manual1/05_dr.tif  \n",
      "  inflating: data/HRF/manual1/05_g.tif  \n",
      "  inflating: data/HRF/manual1/05_h.tif  \n",
      "  inflating: data/HRF/manual1/06_dr.tif  \n",
      "  inflating: data/HRF/manual1/06_g.tif  \n",
      "  inflating: data/HRF/manual1/06_h.tif  \n",
      "  inflating: data/HRF/manual1/07_dr.tif  \n",
      "  inflating: data/HRF/manual1/07_g.tif  \n",
      "  inflating: data/HRF/manual1/07_h.tif  \n",
      "  inflating: data/HRF/manual1/08_dr.tif  \n",
      "  inflating: data/HRF/manual1/08_g.tif  \n",
      "  inflating: data/HRF/manual1/08_h.tif  \n",
      "  inflating: data/HRF/manual1/09_dr.tif  \n",
      "  inflating: data/HRF/manual1/09_g.tif  \n",
      "  inflating: data/HRF/manual1/09_h.tif  \n",
      "  inflating: data/HRF/manual1/10_dr.tif  \n",
      "  inflating: data/HRF/manual1/10_g.tif  \n",
      "  inflating: data/HRF/manual1/10_h.tif  \n",
      "  inflating: data/HRF/manual1/11_dr.tif  \n",
      "  inflating: data/HRF/manual1/11_g.tif  \n",
      "  inflating: data/HRF/manual1/11_h.tif  \n",
      "  inflating: data/HRF/manual1/12_dr.tif  \n",
      "  inflating: data/HRF/manual1/12_g.tif  \n",
      "  inflating: data/HRF/manual1/12_h.tif  \n",
      "  inflating: data/HRF/manual1/13_dr.tif  \n",
      "  inflating: data/HRF/manual1/13_g.tif  \n",
      "  inflating: data/HRF/manual1/13_h.tif  \n",
      "  inflating: data/HRF/manual1/14_dr.tif  \n",
      "  inflating: data/HRF/manual1/14_g.tif  \n",
      "  inflating: data/HRF/manual1/14_h.tif  \n",
      "  inflating: data/HRF/manual1/15_dr.tif  \n",
      "  inflating: data/HRF/manual1/15_g.tif  \n",
      "  inflating: data/HRF/manual1/15_h.tif  \n",
      "   creating: data/HRF/mask/\n",
      "  inflating: data/HRF/mask/01_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/01_g_mask.tif  \n",
      "  inflating: data/HRF/mask/01_h_mask.tif  \n",
      "  inflating: data/HRF/mask/02_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/02_g_mask.tif  \n",
      "  inflating: data/HRF/mask/02_h_mask.tif  \n",
      "  inflating: data/HRF/mask/03_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/03_g_mask.tif  \n",
      "  inflating: data/HRF/mask/03_h_mask.tif  \n",
      "  inflating: data/HRF/mask/04_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/04_g_mask.tif  \n",
      "  inflating: data/HRF/mask/04_h_mask.tif  \n",
      "  inflating: data/HRF/mask/05_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/05_g_mask.tif  \n",
      "  inflating: data/HRF/mask/05_h_mask.tif  \n",
      "  inflating: data/HRF/mask/06_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/06_g_mask.tif  \n",
      "  inflating: data/HRF/mask/06_h_mask.tif  \n",
      "  inflating: data/HRF/mask/07_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/07_g_mask.tif  \n",
      "  inflating: data/HRF/mask/07_h_mask.tif  \n",
      "  inflating: data/HRF/mask/08_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/08_g_mask.tif  \n",
      "  inflating: data/HRF/mask/08_h_mask.tif  \n",
      "  inflating: data/HRF/mask/09_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/09_g_mask.tif  \n",
      "  inflating: data/HRF/mask/09_h_mask.tif  \n",
      "  inflating: data/HRF/mask/10_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/10_g_mask.tif  \n",
      "  inflating: data/HRF/mask/10_h_mask.tif  \n",
      "  inflating: data/HRF/mask/11_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/11_g_mask.tif  \n",
      "  inflating: data/HRF/mask/11_h_mask.tif  \n",
      "  inflating: data/HRF/mask/12_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/12_g_mask.tif  \n",
      "  inflating: data/HRF/mask/12_h_mask.tif  \n",
      "  inflating: data/HRF/mask/13_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/13_g_mask.tif  \n",
      "  inflating: data/HRF/mask/13_h_mask.tif  \n",
      "  inflating: data/HRF/mask/14_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/14_g_mask.tif  \n",
      "  inflating: data/HRF/mask/14_h_mask.tif  \n",
      "  inflating: data/HRF/mask/15_dr_mask.tif  \n",
      "  inflating: data/HRF/mask/15_g_mask.tif  \n",
      "  inflating: data/HRF/mask/15_h_mask.tif  \n",
      "--2025-11-26 17:32:38--  http://personalpages.manchester.ac.uk/staff/niall.p.mcloughlin/DRHAGIS.zip\n",
      "Resolving personalpages.manchester.ac.uk (personalpages.manchester.ac.uk)... 130.88.101.51\n",
      "Connecting to personalpages.manchester.ac.uk (personalpages.manchester.ac.uk)|130.88.101.51|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://personalpages.manchester.ac.uk/staff/niall.p.mcloughlin/DRHAGIS.zip [following]\n",
      "--2025-11-26 17:32:38--  https://personalpages.manchester.ac.uk/staff/niall.p.mcloughlin/DRHAGIS.zip\n",
      "Connecting to personalpages.manchester.ac.uk (personalpages.manchester.ac.uk)|130.88.101.51|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2025-11-26 17:32:39 ERROR 404: Not Found.\n",
      "\n",
      "preparing data\n",
      "DRIVE prepared\n",
      "DRIVE A/V prepared\n",
      "CHASE-DB prepared\n",
      "Resizing HRF images (**only** for training, but we resize all because A/V training set is test set on Vessels)\n",
      "\n",
      "  0% 0/45 [00:00<?, ?it/s]/usr/local/envs/lwnet/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "100% 45/45 [00:22<00:00,  2.04it/s]\n",
      "HRF prepared\n",
      "preparing HRF training set for A/V segmentation:\n",
      "100% 30/30 [00:06<00:00,  4.48it/s]\n",
      "HRF A/V prepared\n",
      "STARE prepared\n",
      "AV-WIDE prepared\n",
      "Traceback (most recent call last):\n",
      "  File \"get_public_data.py\", line 379, in <module>\n",
      "    all_im_names = sorted(os.listdir(path_ims), key=lambda s: s.split(\"_\")[0] )\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/DR-HAGIS/images'\n",
      "total 28\n",
      "drwxr-xr-x  7 root root 4096 Nov 26 17:32 .\n",
      "drwxr-xr-x  8 root root 4096 Nov 26 17:32 ..\n",
      "drwxrwxr-x  5 root root 4096 Nov 26 17:33 AV-WIDE\n",
      "drwxrwxr-x  5 root root 4096 Nov 26 17:32 CHASEDB\n",
      "drwxrwxr-x  8 root root 4096 Nov 26 17:32 DRIVE\n",
      "drwxr-xr-x 10 root root 4096 Nov 26 17:33 HRF\n",
      "drwxrwxr-x  5 root root 4096 Nov 26 17:33 STARE\n"
     ]
    }
   ],
   "source": [
    "# Download datasets\n",
    "!source activate lwnet && python get_public_data.py\n",
    "\n",
    "# Verify datasets\n",
    "!ls -la data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train-drive"
   },
   "source": [
    "## 5. Train Model on DRIVE Dataset\n",
    "\n",
    "Training a W-Net model on the DRIVE dataset.\n",
    "\n",
    "**Training time:** ~20-30 minutes on Colab GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q torch torchvision numpy pandas matplotlib Pillow scikit-image scikit-learn\n",
    "# !pip show torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-drive-code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/lwnet/utils/paired_transforms_tv04.py:19: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "* Training on device \n",
      "* Creating Dataloaders, batch size = 4, workers = 0\n",
      "* Instantiating a wnet model\n",
      "Total params: 68,482\n",
      "* Instantiating loss function BCEWithLogitsLoss()\n",
      "* Starting to train\n",
      " ----------\n",
      "Cycle 1/20\n",
      "  0% 0/50 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/content/lwnet/train_cyclical.py\"\u001b[0m, line \u001b[35m310\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    m1, m2, m3=\u001b[31mtrain_model\u001b[0m\u001b[1;31m(model, optimizer, criterion, train_loader, val_loader, scheduler, grad_acc_steps, metric, experiment_path)\u001b[0m\n",
      "               \u001b[31m~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/content/lwnet/train_cyclical.py\"\u001b[0m, line \u001b[35m160\u001b[0m, in \u001b[35mtrain_model\u001b[0m\n",
      "    tr_logits, tr_labels, tr_loss = \u001b[31mtrain_one_cycle\u001b[0m\u001b[1;31m(train_loader, model, criterion, optimizer, scheduler, grad_acc_steps, cycle)\u001b[0m\n",
      "                                    \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/content/lwnet/train_cyclical.py\"\u001b[0m, line \u001b[35m145\u001b[0m, in \u001b[35mtrain_one_cycle\u001b[0m\n",
      "    tr_logits, tr_labels, tr_loss, tr_lr = \u001b[31mrun_one_epoch\u001b[0m\u001b[1;31m(train_loader, model, criterion, optimizer=optimizer,\u001b[0m\n",
      "                                           \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                                                  \u001b[1;31mscheduler=scheduler, grad_acc_steps=grad_acc_steps, assess=assess)\u001b[0m\n",
      "                                                  \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/content/lwnet/train_cyclical.py\"\u001b[0m, line \u001b[35m92\u001b[0m, in \u001b[35mrun_one_epoch\u001b[0m\n",
      "    for i_batch, (inputs, labels) in \u001b[31menumerate\u001b[0m\u001b[1;31m(loader)\u001b[0m:\n",
      "                                     \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/usr/local/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m732\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    data = self._next_data()\n",
      "  File \u001b[35m\"/usr/local/lib/python3.13/site-packages/torch/utils/data/dataloader.py\"\u001b[0m, line \u001b[35m788\u001b[0m, in \u001b[35m_next_data\u001b[0m\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \u001b[35m\"/usr/local/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\"\u001b[0m, line \u001b[35m52\u001b[0m, in \u001b[35mfetch\u001b[0m\n",
      "    data = [\u001b[31mself.dataset\u001b[0m\u001b[1;31m[idx]\u001b[0m for idx in possibly_batched_index]\n",
      "            \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/content/lwnet/utils/get_loaders.py\"\u001b[0m, line \u001b[35m52\u001b[0m, in \u001b[35m__getitem__\u001b[0m\n",
      "    img, target = \u001b[31mself.transforms\u001b[0m\u001b[1;31m(img, target)\u001b[0m\n",
      "                  \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/content/lwnet/utils/paired_transforms_tv04.py\"\u001b[0m, line \u001b[35m73\u001b[0m, in \u001b[35m__call__\u001b[0m\n",
      "    img, target = \u001b[31mt\u001b[0m\u001b[1;31m(img, target)\u001b[0m\n",
      "                  \u001b[31m~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/content/lwnet/utils/paired_transforms_tv04.py\"\u001b[0m, line \u001b[35m463\u001b[0m, in \u001b[35m__call__\u001b[0m\n",
      "    return t(img, target)\n",
      "  File \u001b[35m\"/content/lwnet/utils/paired_transforms_tv04.py\"\u001b[0m, line \u001b[35m1269\u001b[0m, in \u001b[35m__call__\u001b[0m\n",
      "    return \u001b[31mF.affine\u001b[0m\u001b[1;31m(img, *ret, resample=self.resample, fill=self.fill)\u001b[0m, \\\n",
      "           \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mTypeError\u001b[0m: \u001b[35maffine() got an unexpected keyword argument 'resample'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!source activate lwnet && python train_cyclical.py \\\n",
    "    --csv_train data/DRIVE/train.csv \\\n",
    "    --cycle_lens 20/50 \\\n",
    "    --model_name wnet \\\n",
    "    --save_path wnet_drive \\\n",
    "    --device cuda:0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "generate-preds"
   },
   "source": [
    "## 6. Generate Predictions\n",
    "\n",
    "Generate segmentation predictions on the DRIVE test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate-code"
   },
   "outputs": [],
   "source": [
    "!source activate lwnet && python generate_results.py \\\n",
    "    --config_file experiments/wnet_drive/config.cfg \\\n",
    "    --dataset DRIVE \\\n",
    "    --device cuda:0\n",
    "\n",
    "print(\"\\n✓ Predictions generated in results/DRIVE/experiments/wnet_drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate"
   },
   "source": [
    "## 7. Evaluate Performance\n",
    "\n",
    "Compute performance metrics (AUC, Dice, etc.) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate-code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"analyze_results.py\", line 8, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/usr/local/envs/lwnet/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 2320, in <module>\n",
      "    switch_backend(rcParams[\"backend\"])\n",
      "  File \"/usr/local/envs/lwnet/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 260, in switch_backend\n",
      "    class backend_mod(matplotlib.backend_bases._Backend):\n",
      "  File \"/usr/local/envs/lwnet/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 261, in backend_mod\n",
      "    locals().update(vars(importlib.import_module(backend_name)))\n",
      "  File \"/usr/local/envs/lwnet/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "ModuleNotFoundError: No module named 'matplotlib_inline'\n"
     ]
    }
   ],
   "source": [
    "!source activate lwnet && python analyze_results.py \\\n",
    "    --path_train_preds results/DRIVE/experiments/wnet_drive \\\n",
    "    --path_test_preds results/DRIVE/experiments/wnet_drive \\\n",
    "    --train_dataset DRIVE \\\n",
    "    --test_dataset DRIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize"
   },
   "source": [
    "## 8. Visualize Results (Optional)\n",
    "\n",
    "Display some predictions alongside ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-code"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Get a sample image\n",
    "pred_files = sorted(glob.glob('results/DRIVE/experiments/wnet_drive/*.png'))\n",
    "\n",
    "if pred_files:\n",
    "    sample_file = pred_files[0]\n",
    "    sample_name = os.path.basename(sample_file).replace('.png', '')\n",
    "    \n",
    "    # Load images\n",
    "    img_path = f'data/DRIVE/images/{sample_name}.png'\n",
    "    gt_path = f'data/DRIVE/manual/{sample_name}.png'\n",
    "    pred_path = sample_file\n",
    "    \n",
    "    if os.path.exists(img_path) and os.path.exists(gt_path):\n",
    "        img = Image.open(img_path)\n",
    "        gt = Image.open(gt_path)\n",
    "        pred = Image.open(pred_path)\n",
    "        \n",
    "        # Display\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axes[0].imshow(img)\n",
    "        axes[0].set_title('Original Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(gt, cmap='gray')\n",
    "        axes[1].set_title('Ground Truth')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(pred, cmap='gray')\n",
    "        axes[2].set_title('Prediction')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No prediction files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-results"
   },
   "source": [
    "## 9. Download Results\n",
    "\n",
    "Compress and download the trained model and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-code"
   },
   "outputs": [],
   "source": [
    "# Compress results\n",
    "!zip -r lwnet_results.zip experiments/wnet_drive results/DRIVE/experiments/wnet_drive\n",
    "\n",
    "# Download (this will trigger a download in your browser)\n",
    "from google.colab import files\n",
    "files.download('lwnet_results.zip')\n",
    "\n",
    "print(\"✓ Results compressed and ready for download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "additional-experiments"
   },
   "source": [
    "## Additional Experiments\n",
    "\n",
    "### Train on CHASE-DB\n",
    "\n",
    "```python\n",
    "!python train_cyclical.py \\\n",
    "    --csv_train data/CHASEDB/train.csv \\\n",
    "    --cycle_lens 40/50 \\\n",
    "    --model_name wnet \\\n",
    "    --save_path wnet_chasedb \\\n",
    "    --device cuda:0\n",
    "```\n",
    "\n",
    "### Cross-Dataset Evaluation\n",
    "\n",
    "```python\n",
    "# Generate predictions on CHASE-DB using DRIVE model\n",
    "!python generate_results.py \\\n",
    "    --config_file experiments/wnet_drive/config.cfg \\\n",
    "    --dataset CHASEDB \\\n",
    "    --device cuda:0\n",
    "\n",
    "# Evaluate cross-dataset performance\n",
    "!python analyze_results.py \\\n",
    "    --path_train_preds results/DRIVE/experiments/wnet_drive \\\n",
    "    --path_test_preds results/CHASEDB/experiments/wnet_drive \\\n",
    "    --train_dataset DRIVE \\\n",
    "    --test_dataset CHASEDB\n",
    "```\n",
    "\n",
    "### Train on HRF (Higher Resolution)\n",
    "\n",
    "```python\n",
    "!python train_cyclical.py \\\n",
    "    --csv_train data/HRF/train.csv \\\n",
    "    --cycle_lens 30/50 \\\n",
    "    --model_name wnet \\\n",
    "    --save_path wnet_hrf_1024 \\\n",
    "    --im_size 1024 \\\n",
    "    --batch_size 2 \\\n",
    "    --grad_acc_steps 1 \\\n",
    "    --device cuda:0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "notes"
   },
   "source": [
    "## Notes\n",
    "\n",
    "- **Runtime Limits:** Colab has session time limits. For long training, consider Colab Pro or save checkpoints regularly.\n",
    "- **Storage:** Colab provides limited storage. Clean up datasets/results if needed.\n",
    "- **GPU Memory:** If you encounter OOM errors, reduce batch size or image size.\n",
    "- **Persistence:** Files in Colab are temporary. Download important results before session ends.\n",
    "\n",
    "## References\n",
    "\n",
    "```\n",
    "The Little W-Net That Could: State-of-the-Art Retinal Vessel Segmentation with Minimalistic Models\n",
    "Adrian Galdran, André Anjos, Jose Dolz, Hadi Chakor, Hervé Lombaert, Ismail Ben Ayed\n",
    "https://arxiv.org/abs/2009.01907, Sep. 2020\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
